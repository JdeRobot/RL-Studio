settings:
  mode: training # training, retraining
  task: follow_lane_carla # follow_line_gazebo, follow_lane_gazebo
  algorithm: qlearn # qlearn
  simulator: carla # openai, carla, gazebo, sumo
  environment_set: carla_environments # gazebo_environments, carla_environments
  env: follow_lane # Town01, simple, nurburgring, montreal, curves, simple_laser, manual, autoparking
  agent: auto_carla # f1, autoparkingRL, auto_carla, mountain_car, robot_mesh, cartpole, turtlebot
  actions: carla_simple # simple, medium, hard, test, autoparking_simple
  states: sp1 # sp1 (simplified perception with 1 point), sp3 (simplified perception with 3 points), spn (simplified perception with n points)
  rewards: follow_right_lane_only_center #
  framework: _
  total_episodes: 500
  training_time: 12
  models_dir: "./checkpoints"
  logs_dir: "./logs"
  metrics_dir: "./metrics"
  recorder_carla_dir: "./recorders"

ros:
  ros_master_uri: "11311"
  gazebo_master_uri: "11345"

carla:
  carla_server: localhost
  carla_client: 2000

retraining:
  qlearn:
    retrain_qlearn_model_name: "20230123-161229_Circuit-simple_States-sp1_Actions-simple_Rewards-follow_right_lane_only_center_epsilon-0.399_epoch-291_step-15001_reward-136707-qtable.npy"

inference:
  qlearn:
    inference_qlearn_model_name:

algorithm:
  qlearn:
    alpha: 0.7
    epsilon: 0.95
    epsilon_min: 0.05
    gamma: 0.9

agents:
  auto_carla:
    camera_params:
      width: 640
      height: 480
      center_image: 320
      raw_image: False
      image_resizing: 100
      new_image_size: 32
      num_regions: 16
      lower_limit: 220

states:
  sp1:
    0: [100]
  sp4:
    0: [30, 60, 100, 120]
  sp5:
    0: [3, 5, 10, 15, 20]
  spn:
    0: [50, 120, 180]

actions:
  carla_simple:
    0: [1, -0.2]
    1: [1, 0]
    2: [1, 0.2]
  simple:
    0: [2, -1]
    1: [3, 0]
    2: [2, 1]
  medium:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
    3: [1, 1.5]
    4: [1, -1.5]
  hard:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
    3: [1.5, 1]
    4: [1.5, -1]
    5: [1, -1.5]
    6: [1, -1.5]
  test:
    0: [0, 0]

rewards:
  follow_right_lane_only_center:
    from_10: 10
    from_02: 2
    from_01: 1
    penal: -100
    min_reward: 5_000
    highest_reward: 100
  follow_right_lane_center_v_step:
    from_10: 10
    from_02: 2
    from_01: 1
    penal: -100
    min_reward: 5_000
    highest_reward: 100

carla_environments:
  follow_lane:
    env_name: CarlaEnv-v0
    car: model1
    #sync_mode: True
    weather: ClearNoon #dynamic, argparse
    traffic_pedestrians: False
    city_lights: False
    car_lights: False
    estimated_steps: 500
    save_episodes: 10
    save_every_step: 50
    init_pose:
    goal_pose:
    filter: vehicle.*
    generation: "2"
    rolename: "hero" #name
    gamma: 2.2 #for camera
    sync: True #syncronous mode or async
    alternate_pose: False
    town: Town07 #Town01, Town02, Town03, Town04, Town05, Town06, Town07, Town10HD, Town11
    # Town01_Opt, Town02_Opt, Town03_Opt, Town04_Opt, Town05_Opt, Town10HD_Opt
    waypoints_meters: 5 #distance between waypoints in meters
    waypoints_init: 1 #Town07: (20, -1, 945) 951, #Town01: 879 crash testing, 839 init straight lane
    waypoints_target: 1249 #Town07: (57, -1, 1249), #Town01: 959, 961
    waypoints_lane_id: -1 # -1: right lane from south to north
    waypoints_road_id: 8 # Town07: (20)-920-21-39-57, #Town01: 8
    max_target_waypoint_distance: 3 # distance to finish waypoint
