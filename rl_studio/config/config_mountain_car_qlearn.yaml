settings:
  output_dir: "./logs/"
  save_model: True
  save_positions: True
  telemetry: False
  mode: inference
  agent: mountain_car
  algorithm: qlearn

actions:
    0: [ 0, 0, 0, 0]
    1: [ 0, 0, -0.9, -0.9]
    2: [ 0.9, 0.9, 0, 0]

agent:
  mountain_car:
    camera_params:
      witdh: 640
      height: 480

environments:
    env_name: MyMountainCarEnv-v0
    circuit_name: simple
    training_type: qlearn_camera
    launchfile: my_mountain_world.launch
    environment_folder: mountain_car
    robot_name: my_robot
    start_pose: 1, 2
    alternate_pose: True
    estimated_steps: 4000
    sensor: camera
    circuit_positions_set: #  x, y, z, roll, pith, ???. yaw
      - [ 0, 53.462, -41.988, 0.004, 0, 0, 1.57, -1.57 ]
      - [ 1, 53.462, -8.734, 0.004, 0, 0, 1.57, -1.57 ]
      - [ 2, 39.712, -30.741, 0.004, 0, 0, 1.56, 1.56 ]
      - [ 3, -6.861, -36.481, 0.004, 0, 0.01, -0.858, 0.613 ]
      - [ 4, 20.043, 37.130, 0.003, 0, 0.103, -1.4383, -1.4383 ]
    goal: 6.5
    pos_x: -4
    pos_y: -2
    pos_z: 3
    max_steps: 5000

  # manual:
  #   env_name: F1Env-v0
  #   circuit_name: manual
  #   training_type: qlearn_camera
  #   launch: simple_circuit.launch
  #   start_pose: 0
  #   alternate_pose: False
  #   estimated_steps: 4000
  #   sensor: camera

inference:
  inference_file: /home/ruben/Desktop/my-RL-Studio/rl_studio/checkpoints/mountain_car/1_20221226_1928_epsilon_0.01_QTABLE.pkl
  actions_file: /home/ruben/Desktop/my-RL-Studio/rl_studio/checkpoints/mountain_car/actions_set_20221226_1814

algorithm:
    alpha: 0.9
    epsilon: 0.95
    gamma: 0.9
    epsilon_discount: 0.99995
