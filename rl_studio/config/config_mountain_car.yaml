settings:
  output_dir: "./logs/"
  save_model: True
  save_positions: True
  telemetry: False

actions:
    actions_number: 3
    actions_set: simple
    available_actions:
      # [lineal, angular]
      simple:
        0: [ 0, 0, 0, 0]
        1: [ 0, 0, -0.9, -0.9]
        2: [ 0.9, 0.9, 0, 0]

agent:
  mountain_car:
    camera_params:
      witdh: 640
      height: 480

environments:
  simple:
    env_name: MyMountainCarEnv-v0
    circuit_name: simple
    training_type: qlearn_camera
    launchfile: my_mountain_world.launch
    environment_folder: mountain_car
    robot_name: my_robot
    start_pose: 1, 2
    alternate_pose: True
    estimated_steps: 4000
    sensor: camera
    circuit_positions_set: #  x, y, z, roll, pith, ???. yaw
      - [ 0, 53.462, -41.988, 0.004, 0, 0, 1.57, -1.57 ]
      - [ 1, 53.462, -8.734, 0.004, 0, 0, 1.57, -1.57 ]
      - [ 2, 39.712, -30.741, 0.004, 0, 0, 1.56, 1.56 ]
      - [ 3, -6.861, -36.481, 0.004, 0, 0.01, -0.858, 0.613 ]
      - [ 4, 20.043, 37.130, 0.003, 0, 0.103, -1.4383, -1.4383 ]
    goal: 6.5
    pos_x: -4
    pos_y: -2
    pos_z: 3
    max_steps: 5000

  # manual:
  #   env_name: F1Env-v0
  #   circuit_name: manual
  #   training_type: qlearn_camera
  #   launch: simple_circuit.launch
  #   start_pose: 0
  #   alternate_pose: False
  #   estimated_steps: 4000
  #   sensor: camera


algorithm:
    qlearn_mountain:
      alpha: 0.9
      epsilon: 0.95
      gamma: 0.9
      epsilon_discount: 0.99995

    dqn:

    sarsa:
