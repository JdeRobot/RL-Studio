settings:
  output_dir: "./logs/"
  save_model: True
  save_positions: True
  telemetry: False
  logging_level: info
  mode: inference
  agent: cartpole
  algorithm: qlearn

# TODO make this section optional
actions:
    available_actions:
      simple:

agent:
  cartpole:
    # TODO To be removed
    camera_params:
      witdh: 640
    height: 480

environments:
    env_name: myCartpole-v0
    environment_folder: cartpole
#    runs: 20000
    angle_bins: 100
    pos_bins: 100
    runs: 100
    full_experimentation_runs: 0
    update_every: 1000
    save_every: 10000
    show_every: 100
    objective_reward: 500
#    block_experience_batch: False
    block_experience_batch: False
  #  random_start_level: 0.05
    random_start_level: 0 # Number between 0 and 1 that indicates the difficulty of the start position
    random_perturbations_level: 0 # Number between 0 and 1 that indicates the frequency of the random perturbations
    perturbations_intensity_std: 0 # Number between 0 and 1 that indicates the standard deviation of perturbations intensity
    initial_pole_angle: 0.3
    non_recoverable_angle: 0.7
#    previously_trained_agent: /home/ruben/Desktop/my-RL-Studio/rl_studio/logs/cartpole/qlearning/checkpoints/20221116_2001_epsilon_0.01_QTABLE_avg_ 179.357.pkl
    reward_value: 1
    punish: 0
    reward_shaping: 0

inference:
    inference_file: /home/ruben/Desktop/my-RL-Studio/rl_studio/checkpoints/cartpole/qlearn_models/20221116_0028_epsilon_0_267.0_QTABLE.pkl_avg_.pkl
    actions_file: /home/ruben/Desktop/my-RL-Studio/rl_studio/logs/cartpole/qlearning/checkpoints/actions_set_20221109_2108

algorithm:
    alpha: 0.9
    epsilon: 0.5
    gamma: 0.9
    epsilon_discount: 0.9999995
