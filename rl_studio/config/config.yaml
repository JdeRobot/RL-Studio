#####################################################################################
# General configuration file to launch RL-Studio in the training or inference mode
#
# Warning: it is not practical use it as a launch file!
#       this file contains all parameters for whole tasks, agents, simulators,
#       frameworks...as a didactic proposes. It is recommended creating a new specific
#       config file for a dedicated task, with the form:
#             config_mode_task_algorithm_agent_simulator.yaml
#####################################################################################

#####################################################################################
# General settings
#
# Main Options:
#
# mode: training, retraining, inference
# task: follow_line, follow_lane
# algorithm: qlearn, dqn, ddpg, ppo
# simulator: openai, carla, gazebo
# environment_set: gazebo_environments # gazebo_environments, carla_environments
# env: simple, nurburgring, montreal, curves, simple_laser, manual, autoparking
# agent: f1, autoparking
# actions: continuous, simple, medium, hard, test, autoparking_simple
# states: image, sp1, sp3, spn
# rewards: discrete_follow_line, linear_follow_line, discrete_follow_right_lane, discrete_autoparking
#
#####################################################################################
settings:
  mode: training # training, retraining, inference
  task: follow_lane_gazebo # follow_line_gazebo, follow_lane_gazebo, autoparking_gazebo
  algorithm: ddpg # qlearn, dqn, ddpg, ppo
  simulator: gazebo # openai, carla, gazebo
  environment_set: gazebo_environments # gazebo_environments, carla_environments
  env: simple # simple, nurburgring, montreal, curves, simple_laser, manual, autoparking
  agent: f1 # f1, autoparkingRL, auto_carla, mountain_car, robot_mesh, cartpole, turtlebot
  actions: continuous # continuous, simple, medium, hard, test, autoparking_simple
  states: sp1 #image, sp1, sp3, spn
  rewards: discrete_follow_right_lane # discrete_follow_line, linear_follow_line, discrete_follow_right_lane, discrete_autoparking
  framework: TensorFlow # TensorFlow, Pytorch
  models_dir: "./checkpoints"
  logs_dir: "./logs"
  metrics_dir: "./metrics"
  total_episodes: 50_000
  training_time: 6

#####################################################################################
# ROS general settings
#####################################################################################
ros:
  ros_master_uri: "11311"
  gazebo_master_uri: "11345"

#####################################################################################
# Carla simulator general settings
#####################################################################################
carla:
  prefernvidia: True
  port_rpc:
  port_streaming:
  quality_level:
  render_mode:
  off_screen_mode:

#####################################################################################
# Inference and retraining: loading training files
#####################################################################################
retraining:
  qlearn:
    model_name: DDPG_Actor_conv2d32x64_Critic_conv2d32x64_actionsCont_stateImg_BATCH_CRITIC_Max61351_Epoch-500_State-image_Actions-continuous_inTime-20221018-221521.h5

inference:
  ddpg:
    inference_ddpg_tf_actor_model_name: "DDPG_Actor_conv2d32x64_Critic_conv2d32x64_BESTLAP_ACTOR_Max90069_Epoch226_inTime20221017-163548.h5"
    inference_ddpg_tf_critic_model_name: "DDPG_Actor_conv2d32x64_Critic_conv2d32x64_BESTLAP_CRITIC_Max90069_Epoch226_inTime20221017-163548.h5"

#####################################################################################
# Algorithms parameters
#####################################################################################
algorithm:
  qlearn:
    alpha: 0.2
    epsilon: 0.95
    epsilon_min: 0.05
    gamma: 0.9
  dqn:
    alpha: 0.8
    gamma: 0.9
    epsilon: 0.99
    epsilon_discount: 0.9986
    epsilon_min: 0.05
    model_name: DQN_sp_16x16
    replay_memory_size: 50_000
    min_replay_memory_size: 1000
    minibatch_size: 64
    update_target_every: 5
    memory_fraction: 0.20
    buffer_capacity: 100_000
    batch_size: 64
  sarsa:
  ddpg:
    gamma: 0.9
    tau: 0.005
    std_dev: 0.2
    model_name: DDPG_Actor_conv2d32x64_Critic_conv2d32x64
    replay_memory_size: 50_000
    memory_fraction: 0.20
    critic_lr: 0.002
    actor_lr: 0.001
    buffer_capacity: 100_000
    batch_size: 64

#####################################################################################
# Agent
#####################################################################################
agents:
  f1:
    camera_params:
      width: 640
      height: 480
      center_image: 320
      raw_image: False
      image_resizing: 100
      new_image_size: 32
      num_regions: 16
  autoparking:
    camera_params:
      width: 640
      height: 480
      center_image: 320
      raw_image: False
      image_resizing: 100
      new_image_size: 32

#####################################################################################
# States
#####################################################################################
states:
  image:
    0: [3]
  sp1:
    0: [10]
  sp3:
    0: [5, 15, 22]
  sp5:
    0: [3, 5, 10, 15, 20]
  spn:
    0: [10]
  sp_curb: #autoparking
    poi: 3
    regions: 16
    pixels_cropping: 200
    sp_curb3:
      0: [5, 15, 22]
    sp5:
      0: [3, 5, 10, 15, 20]
    spn:
      0: [10]

#####################################################################################
# Actions
#####################################################################################
actions:
  simple:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
  medium:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
    3: [1, 1.5]
    4: [1, -1.5]
  hard:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
    3: [1.5, 1]
    4: [1.5, -1]
    5: [1, -1.5]
    6: [1, -1.5]
  test:
    0: [0, 0]
  continuous:
    v: [2, 30]
    w: [-3, 3]
  autoparking_simple:
    0: [3, 0]
    1: [2, 0]
    2: [1, 0]
    3: [0, 0]
    4: [-1, 0]

#####################################################################################
# Rewards
#####################################################################################
rewards:
  followline_center:
    from_10: 10
    from_02: 2
    from_01: 1
    penal: -100
    min_reward: 5_000
    highest_reward: 100
  followline_center_v_w_linear: # only for continuous actions
    beta_0: 3
    beta_1: -0.1
    penal: 0
    min_reward: 1_000
    highest_reward: 100

#####################################################################################
# Environments: Gazebo, Carla, OpenAI
#####################################################################################
gazebo_environments:
  simple:
    env_name: F1Env-v0
    circuit_name: simple
    training_type: qlearn_camera #qlearn_camera, ddpg, dqn
    launchfile: simple_circuit.launch
    environment_folder: f1
    robot_name: f1_renault
    model_state_name: f1_camera_parking # autoparking
    start_pose: 0 # 0, 1, 2, 3, 4
    alternate_pose: False
    estimated_steps: 15_000
    sensor: camera
    save_episodes: 50
    save_every_step: 1_000
    lap_completed: False
    save_model: True
    save_positions: True
    debug_level: DEBUG
    telemetry: False
    telemetry_mask: False
    plotter_graphic: False
    circuit_positions_set:
      0: [53.462, -41.988, 0.004, 0, 0, 1.57, -1.57]
      1: [53.462, -8.734, 0.004, 0, 0, 1.57, -1.57]
      2: [39.712, -30.741, 0.004, 0, 0, 1.56, 1.56]
      3: [-6.861, -36.481, 0.004, 0, 0.01, -0.858, 0.613]
      4: [20.043, 37.130, 0.003, 0, 0.103, -1.4383, -1.4383]
  nurburgring:
    env_name: F1Env-v0
    circuit_name: nurburgring
    training_type: qlearn_camera
    launchfile: nurburgring_line.launch
    environment_folder: f1
    robot_name: f1_renault
    start_pose: 0
    alternate_pose: True
    estimated_steps: 3500
    sensor: camera
    save_episodes: 50
    save_every_step: 1_000
    lap_completed: False
    save_model: True
    save_positions: True
    debug_level: DEBUG
    telemetry: False
    telemetry_mask: False
    plotter_graphic: False
    circuit_positions_set:
      0: [-32.3188, 12.2921, 0, 0.0014, 0.0049, -0.2727, 0.9620]
      1: [-30.6566, -21.4929, 0, 0.0014, 0.0049, -0.4727, 0.8720]
      2: [28.0352, -17.7923, 0, 0.0001, 0.0051, -0.028, 1]
      3: [88.7408, -31.7120, 0, 0.0030, 0.0041, -0.1683, 0.98]
      4: [-73.2172, 11.8508, 0, 0.0043, -0.0027, 0.8517, 0.5173]
      5: [-73.6672, 37.4308, 0, 0.0043, -0.0027, 0.8517, 0.5173]
  montreal:
    env_name: F1Env-v0
    circuit_name: montreal
    training_type: qlearn_camera
    launchfile: montreal_line.launch
    environment_folder: f1
    robot_name: f1_renault
    start_pose: 0
    alternate_pose: True
    estimated_steps: 8000
    sensor: camera
    save_episodes: 50
    save_every_step: 1_000
    lap_completed: False
    save_model: True
    save_positions: True
    debug_level: DEBUG
    telemetry: False
    telemetry_mask: False
    plotter_graphic: False
    circuit_positions_set:
      0: [-201.88, -91.02, 0, 0.00, 0.001, 0.98, -0.15]
      1: [-278.71, -95.50, 0, 0.00, 0.001, 1, 0.03]
      2: [-272.93, -17.70, 0, 0.0001, 0.001, 0.48, 0.87]
      3: [-132.73, 55.82, 0, 0.0030, 0.0041, -0.02, 0.9991]
      4: [294.99, 91.54, 0, 0.0043, -0.0027, 0.14, 0.99]
  curves:
    env_name: F1Env-v0
    circuit_name: curves
    training_type: qlearn_camera
    launchfile: many_curves.launch
    environment_folder: f1
    robot_name: f1_renault
    start_pose: 0
    alternate_pose: False
    estimated_steps: 4000
    sensor: camera
  simple_laser:
    env_name: F1Env-v0
    circuit_name: simple_laser
    training_type: qlearn_laser
    launchfile: f1_montreal.launch
    environment_folder: f1
    robot_name: f1_renault
    start_pose: 0
    alternate_pose: False
    estimated_steps: 4000
    sensor: laser
  manual:
    env_name: F1Env-v0
    circuit_name: manual
    training_type: qlearn_camera
    launchfile: simple_circuit.launch
    environment_folder: f1
    robot_name: f1_renault
    start_pose: 0
    alternate_pose: True
    estimated_steps: 4000
    sensor: camera
  autoparking:
    env_name: AutoparkingEnv-v0
    circuit_name: autoparking
    training_type: qlearn #qlearn, dqn, qlearn, manual, ddpg
    launchfile: autoparking.launch
    environment_folder: autoparking
    robot_name: f1_camera_parking # autoparking_f1_camera_laser #
    estimated_steps: 50
    sensor: laser #laser, camera_laser, camera
    start_pose: 0
    alternate_pose: False
    save_episodes: 50
    save_every_step: 1_000
    lap_completed: False
    save_model: True
    save_positions: True
    debug_level: DEBUG
    telemetry: False
    telemetry_mask: False
    plotter_graphic: False
    circuit_positions_set:
      0: [5.81294, 4.30243, 0.025329, 0.00013, 0.010376, 3.138] #x, y, z, roll, pitch, waw
      1: [10.0231, -0.720526, 0.025333, 0.000116, 0.010372, 2.5]
      2: [9.81003, 16.7248, 0.025296, 0.0002, 0.010271, -1.92009]
      3: [15.1722, 4.66392, 0.025344, 7.6e-05, 0.010362, -3.12394]
      4: [14.2657, -2.26994, 0.02533, 5.1e-05, 0.010363, -3.12403]
      5: [18.4119, 22.1479, 0.025338, 8.1e-05, 0.010356, -3.12407]
      6: [8.43921, -2.90071, 0.025338, 8.1e-05, 0.010356, 1.55485]
    parking_spot_position_x: 2
    parking_spot_position_y: 4.30

carla_environments:
