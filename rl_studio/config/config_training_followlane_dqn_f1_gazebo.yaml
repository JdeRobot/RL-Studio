settings:
  mode: training # training, retraining, inference
  task: follow_lane_gazebo # follow_line_gazebo, follow_lane_gazebo, autoparking_gazebo
  algorithm: dqn # qlearn, dqn, ddpg, ppo
  simulator: gazebo # openai, carla, gazebo, sumo
  environment_set: gazebo_environments # gazebo_environments, carla_environments
  env: simple # simple, nurburgring, montreal, curves, simple_laser, manual, autoparking
  agent: f1 # f1, autoparkingRL, auto_carla, mountain_car, robot_mesh, cartpole, turtlebot
  actions: simple # simple, medium, hard, test
  states: sp1 #image, sp1 (simplified perception with 1 point), sp3 (simplified perception with 3 points), spn (simplified perception with n points)
  rewards: follow_right_lane_only_center # follow_right_lane_only_center, follow_right_lane_center_v_step
  framework: TensorFlow # TensorFlow, Pytorch
  total_episodes: 1_000
  training_time: 5
  models_dir: "./checkpoints"
  logs_dir: "./logs"
  metrics_dir: "./metrics"

ros:
  ros_master_uri: "11311"
  gazebo_master_uri: "11345"

retraining:
  dqn:
    retrain_dqn_tf_model_name: "DQN_sp_16x16_LAPCOMPLETED_Max165_Epoch1_inTime20221222-171814.model"

inference:
  dqn:
    inference_dqn_tf_model_name:

algorithm:
  dqn:
    alpha: 0.8
    gamma: 0.9
    epsilon: 0.95 # in Retraining mode is convenient to reduce, i.e. 0.45
    epsilon_discount: 0.9986
    epsilon_min: 0.05
    model_name: DQN_sp_16x16 #DQN_im_32x64
    replay_memory_size: 50_000
    min_replay_memory_size: 1000
    minibatch_size: 64
    update_target_every: 5
    memory_fraction: 0.20
    buffer_capacity: 100_000
    batch_size: 64

agents:
  f1:
    camera_params:
      width: 640
      height: 480
      center_image: 320
      raw_image: False
      image_resizing: 100
      new_image_size: 32
      num_regions: 16
      lower_limit: 220

states:
  image:
    0: [50]
  sp1:
    0: [50]
  sp3:
    0: [5, 15, 22]
  sp5:
    0: [3, 5, 10, 15, 20]
  spn:
    0: [10]

actions:
  simple:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
  medium:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
    3: [1, 1.5]
    4: [1, -1.5]
  hard:
    0: [3, 0]
    1: [2, 1]
    2: [2, -1]
    3: [1.5, 1]
    4: [1.5, -1]
    5: [1, -1.5]
    6: [1, -1.5]
  test:
    0: [0, 0]

rewards:
  follow_right_lane_only_center:
    from_10: 10
    from_02: 2
    from_01: 1
    penal: -100
    min_reward: 5_000
    highest_reward: 100
  follow_right_lane_center_v_step:
    from_10: 10
    from_02: 2
    from_01: 1
    penal: -100
    min_reward: 5_000
    highest_reward: 100

gazebo_environments:
  simple:
    env_name: F1Env-v0
    circuit_name: simple
    launchfile: simple_circuit_no_wall.launch
    environment_folder: f1
    robot_name: f1_renault
    model_state_name: f1_renault_multicamera_multilaser # f1_renault_multicamera_multilaser, f1_renault
    start_pose: 0 # 0, 1, 2, 3, 4
    alternate_pose: False
    estimated_steps: 15_000
    sensor: camera
    save_episodes: 10
    save_every_step: 1_000
    lap_completed: False
    save_model: True
    save_positions: True
    debug_level: DEBUG
    telemetry: False
    telemetry_mask: False
    plotter_graphic: False
    circuit_positions_set:
      0: [52.462, -41.988, 0.004, 0, 0, 1.57, -1.57]
      #0: [52.800, -12.734, 0.004, 0, 0, 1.57, -1.57] # near to first curve
      #0: [52.800, -8.734, 0.004, 0, 0, 1.57, -1.57] # Finish line
      #0: [53.462, -41.988, 0.004, 0, 0, 1.57, -1.57]
      1: [52.97, -42.06, 0.004, 0, 0, 1.57, -1.57]
      #1: [53.462, -8.734, 0.004, 0, 0, 1.57, -1.57]
      #2: [39.712, -30.741, 0.004, 0, 0, 1.56, 1.56]
      2: [40.2, -30.741, 0.004, 0, 0, 1.56, 1.56]
      #3: [-6.861, -36.481, 0.004, 0, 0.01, -0.858, 0.613]
      3: [0, 31.15, 0.004, 0, 0.01, 0, 0.31]
      #4: [20.043, 37.130, 0.003, 0, 0.103, -1.4383, -1.4383]
      4: [19.25, 43.50, 0.004, 0, 0.0, 1.57, -1.69]
      5: [52.800, -35.486, 0.004, 0, 0, 1.57, -1.57] # near to first curve
